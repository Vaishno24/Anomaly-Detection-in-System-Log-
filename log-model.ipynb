{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:42.538103Z",
     "iopub.status.busy": "2022-10-31T10:19:42.536882Z",
     "iopub.status.idle": "2022-10-31T10:19:42.558533Z",
     "shell.execute_reply": "2022-10-31T10:19:42.557610Z",
     "shell.execute_reply.started": "2022-10-31T10:19:42.538066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/log-anamoly1/anomaly_label.csv\n",
      "/kaggle/input/logfile/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:20:25.509585Z",
     "iopub.status.busy": "2022-10-31T10:20:25.509077Z",
     "iopub.status.idle": "2022-10-31T10:20:25.526285Z",
     "shell.execute_reply": "2022-10-31T10:20:25.524928Z",
     "shell.execute_reply.started": "2022-10-31T10:20:25.509540Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D\n",
    "from keras.layers import Flatten, Dropout, Dense\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from torch.autograd import Variable\n",
    "from torch import IntTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:42.560456Z",
     "iopub.status.busy": "2022-10-31T10:19:42.560070Z",
     "iopub.status.idle": "2022-10-31T10:19:42.622861Z",
     "shell.execute_reply": "2022-10-31T10:19:42.621867Z",
     "shell.execute_reply.started": "2022-10-31T10:19:42.560420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_data</th>\n",
       "      <th>Y_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81109 203615 148 INFO dfs DataNode PacketRespo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81109 203807 222 INFO dfs DataNode PacketRespo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81109 204005 35 INFO dfs FSNamesystem BLOCK Na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81109 204015 308 INFO dfs DataNode PacketRespo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81109 204106 329 INFO dfs DataNode PacketRespo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>81111 101621 24902 INFO dfs DataNode DataXceiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>81111 101735 26595 INFO dfs DataNode PacketRes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>81111 101804 26494 INFO dfs DataNode DataXceiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>81111 101954 26414 INFO dfs DataNode PacketRes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>81111 102017 26347 INFO dfs DataNode DataXceiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 X_data  Y_data\n",
       "0     81109 203615 148 INFO dfs DataNode PacketRespo...       0\n",
       "1     81109 203807 222 INFO dfs DataNode PacketRespo...       0\n",
       "2     81109 204005 35 INFO dfs FSNamesystem BLOCK Na...       0\n",
       "3     81109 204015 308 INFO dfs DataNode PacketRespo...       0\n",
       "4     81109 204106 329 INFO dfs DataNode PacketRespo...       0\n",
       "...                                                 ...     ...\n",
       "1995  81111 101621 24902 INFO dfs DataNode DataXceiv...       0\n",
       "1996  81111 101735 26595 INFO dfs DataNode PacketRes...       0\n",
       "1997  81111 101804 26494 INFO dfs DataNode DataXceiv...       0\n",
       "1998  81111 101954 26414 INFO dfs DataNode PacketRes...       0\n",
       "1999  81111 102017 26347 INFO dfs DataNode DataXceiv...       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../input/logfile/cleaned_data.csv\")\n",
    "data['X_data'] = data['X_data'].apply(lambda s: s.split(' ', 1)[1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:42.626330Z",
     "iopub.status.busy": "2022-10-31T10:19:42.625508Z",
     "iopub.status.idle": "2022-10-31T10:19:42.632129Z",
     "shell.execute_reply": "2022-10-31T10:19:42.631033Z",
     "shell.execute_reply.started": "2022-10-31T10:19:42.626295Z"
    }
   },
   "outputs": [],
   "source": [
    "X = list(data['X_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:42.634764Z",
     "iopub.status.busy": "2022-10-31T10:19:42.633755Z",
     "iopub.status.idle": "2022-10-31T10:19:43.038577Z",
     "shell.execute_reply": "2022-10-31T10:19:43.037572Z",
     "shell.execute_reply.started": "2022-10-31T10:19:42.634728Z"
    }
   },
   "outputs": [],
   "source": [
    "words_in_train = [sent.split() for sent in X] # Splitting the tweet into tokens\n",
    "all_words_train = list(itertools.chain(*words_in_train)) # Making a flatlist of all the words in the corpus\n",
    "all_words = all_words_train  \n",
    "corpus = X  \n",
    "vocab_size = len(set(all_words)) # number of words to keep.\n",
    "embedding_dim = 100 # Dimension of the vector representation for each word \n",
    "max_length = 0\n",
    "for i in range(len(corpus)):\n",
    "    x = word_tokenize(corpus[i])\n",
    "    if len(x) > max_length:\n",
    "        max_length = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:43.040670Z",
     "iopub.status.busy": "2022-10-31T10:19:43.040277Z",
     "iopub.status.idle": "2022-10-31T10:19:43.049122Z",
     "shell.execute_reply": "2022-10-31T10:19:43.048193Z",
     "shell.execute_reply.started": "2022-10-31T10:19:43.040629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of the sequence : 225\n",
      "Size of the vocabulary : 5972\n"
     ]
    }
   ],
   "source": [
    "print(\"Max length of the sequence :\",max_length)\n",
    "print(\"Size of the vocabulary :\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:43.051372Z",
     "iopub.status.busy": "2022-10-31T10:19:43.050976Z",
     "iopub.status.idle": "2022-10-31T10:19:43.612792Z",
     "shell.execute_reply": "2022-10-31T10:19:43.611807Z",
     "shell.execute_reply.started": "2022-10-31T10:19:43.051337Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['X_data'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:43.614346Z",
     "iopub.status.busy": "2022-10-31T10:19:43.614003Z",
     "iopub.status.idle": "2022-10-31T10:19:43.692285Z",
     "shell.execute_reply": "2022-10-31T10:19:43.691353Z",
     "shell.execute_reply.started": "2022-10-31T10:19:43.614314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pad the sequences so that they are all the same length\n",
    "training_sequences = tokenizer.texts_to_sequences(data['X_data'])\n",
    "trainds_vec = tf.keras.preprocessing.sequence.pad_sequences(training_sequences,maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:19:43.693903Z",
     "iopub.status.busy": "2022-10-31T10:19:43.693549Z",
     "iopub.status.idle": "2022-10-31T10:19:44.174234Z",
     "shell.execute_reply": "2022-10-31T10:19:44.173245Z",
     "shell.execute_reply.started": "2022-10-31T10:19:43.693865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape (2000, 225)\n",
      "Resample dataset shape (3862, 225)\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(np.array(trainds_vec), data['Y_data'])\n",
    "print('Original dataset shape', np.array(trainds_vec).shape)\n",
    "print('Resample dataset shape', x_smote.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:20:37.754707Z",
     "iopub.status.busy": "2022-10-31T10:20:37.754342Z",
     "iopub.status.idle": "2022-10-31T10:20:37.763254Z",
     "shell.execute_reply": "2022-10-31T10:20:37.762083Z",
     "shell.execute_reply.started": "2022-10-31T10:20:37.754675Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(x_smote,y_smote,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:20:39.012709Z",
     "iopub.status.busy": "2022-10-31T10:20:39.012317Z",
     "iopub.status.idle": "2022-10-31T10:20:39.019123Z",
     "shell.execute_reply": "2022-10-31T10:20:39.018105Z",
     "shell.execute_reply.started": "2022-10-31T10:20:39.012674Z"
    }
   },
   "outputs": [],
   "source": [
    "Training_labels = tf.keras.utils.to_categorical(Y_train)\n",
    "Testing_labels = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:20:39.591732Z",
     "iopub.status.busy": "2022-10-31T10:20:39.591000Z",
     "iopub.status.idle": "2022-10-31T10:20:50.864925Z",
     "shell.execute_reply": "2022-10-31T10:20:50.863998Z",
     "shell.execute_reply.started": "2022-10-31T10:20:39.591698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 10:20:39.750669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.751741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.752756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.753557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.754321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.755075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:39.756385: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-31 10:20:40.008959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:40.009794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:40.010698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:40.011501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:40.012213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:40.012894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.496181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.497044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.497767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.498480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.499199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.499842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-10-31 10:20:50.506021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 10:20:50.506756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:25:56.779877Z",
     "iopub.status.busy": "2022-10-31T10:25:56.779483Z",
     "iopub.status.idle": "2022-10-31T10:25:57.269989Z",
     "shell.execute_reply": "2022-10-31T10:25:57.268841Z",
     "shell.execute_reply.started": "2022-10-31T10:25:56.779827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 225, 100)          597200    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 225, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 45, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 45, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200)               132000    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 767,762\n",
      "Trainable params: 767,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_size = 64\n",
    "kernel_size = 5\n",
    "pool_size = 5\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length,\n",
    "#                              embeddings_initializer='orthogonal', embeddings_regularizer='L2'),\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(filter_size, kernel_size, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size, padding='same'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=METRICS\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T10:25:57.715914Z",
     "iopub.status.busy": "2022-10-31T10:25:57.715563Z",
     "iopub.status.idle": "2022-10-31T10:26:07.990087Z",
     "shell.execute_reply": "2022-10-31T10:26:07.989010Z",
     "shell.execute_reply.started": "2022-10-31T10:25:57.715883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.6384 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6904 - val_loss: 0.6469 - val_accuracy: 0.6869 - val_precision: 0.6869 - val_recall: 0.6869 - val_auc: 0.7792\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.4159 - accuracy: 0.8174 - precision: 0.8174 - recall: 0.8174 - auc: 0.8953 - val_loss: 0.6858 - val_accuracy: 0.7400 - val_precision: 0.7400 - val_recall: 0.7400 - val_auc: 0.8065\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.1176 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - auc: 0.9914 - val_loss: 0.7914 - val_accuracy: 0.7503 - val_precision: 0.7503 - val_recall: 0.7503 - val_auc: 0.8333\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 0.0442 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - auc: 0.9978 - val_loss: 1.6134 - val_accuracy: 0.6856 - val_precision: 0.6856 - val_recall: 0.6856 - val_auc: 0.7341\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 0.0250 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9922 - auc: 0.9990 - val_loss: 1.1330 - val_accuracy: 0.7245 - val_precision: 0.7245 - val_recall: 0.7245 - val_auc: 0.8023\n"
     ]
    }
   ],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max', restore_best_weights=True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "num_epochs = 5\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Training_labels,\n",
    "    epochs=num_epochs,\n",
    "    batch_size = 128,\n",
    "    validation_data=(X_test, Testing_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
